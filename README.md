# S&P 500 Companies Data Web Scraping

This project involves web scraping features of S&P 500 companies from Wikipedia using Python. The objective is to scrape data on various attributes of these companies, such as ticker symbol, company name, sector, headquarters, date first added to the index, and foundation year. The scraped data is then cleaned and saved into a CSV file for subsequent analysis.
## Project Overview

### Objectives

- **Web Scraping**: Utilize Python libraries BeautifulSoup and Requests to extract data from Wikipedia.
- **Data Cleaning**: Process and clean the scraped data to ensure accuracy and consistency.
- **Data Storage**: Save the cleaned data into a CSV file for further analysis.
- **Data Visualization**: Create a basic visualization in Power BI to demonstrate insights from the data.

### Final Output

The final output of this project includes:

- A CSV file containing a cleaned dataset with information about S&P 500 companies.
- A basic Power BI visualization that provides a demonstration of insights derived from the data.


![Captura de pantalla 2024-07-24 231838](https://github.com/user-attachments/assets/0cd769b2-f590-45ce-b53b-afe5faa60aca)
# Basic Power BI visualization
![Captura de pantalla 2024-07-24 233020](https://github.com/user-attachments/assets/cba7454e-f79c-4b50-a7eb-4515c1c4f563)


## End
You can find me on [LinkedIn](https://www.linkedin.com/in/franco-maldonado-del/).
